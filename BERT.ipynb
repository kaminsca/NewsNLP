{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch pandas datasets scikit-learn\n",
        "!pip install transformers[torch] -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae7GuGEN5Kex",
        "outputId": "b1440031-9590-493a-e9b6-f7e2ffa29b7f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.99)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.39.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.28.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.4.99)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qosfwzev4FEI"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextClassifierDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return item"
      ],
      "metadata": {
        "id": "Rg9n9WmJ89vu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://medium.com/@abdurhmanfayad_73788/fine-tuning-bert-for-a-multi-label-classification-problem-on-colab-5ca5b8759f3f\n",
        "df = pd.read_csv('./processed_data.csv', delimiter='|')\n",
        "train_df, test_df = train_test_split(df, test_size=0.2)\n",
        "print(\"Train dataset head:\")\n",
        "print(train_df)"
      ],
      "metadata": {
        "id": "JOxMjfLO46yp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56969a00-556f-4a46-efae-3f16edd5b71b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset head:\n",
            "                                                content            county  \\\n",
            "1469  new york coronavirus deaths surging new york g...           Bristol   \n",
            "505   steamboat springs county officials echoed gov ...             Routt   \n",
            "863   hanna city danley believes swimmingpool sales ...            Peoria   \n",
            "1571  coronavirus stories provided free public servi...         Middlesex   \n",
            "1126  ambitious billion paycheck protection program ...  East Baton Rouge   \n",
            "...                                                 ...               ...   \n",
            "1261  washington president trump friday abruptly fir...      Androscoggin   \n",
            "1821  one county centrals knowledge bowl teams quali...           Jackson   \n",
            "351   boulder quality biomedical inc ramped producti...        Broomfield   \n",
            "880   chris cuomo says hes lost significant amount w...        Stephenson   \n",
            "561   marcy shortuse move surprised many florida gov...               Lee   \n",
            "\n",
            "              state                source  total_population  \\\n",
            "1469  Massachusetts         theheraldnews            554868   \n",
            "505        Colorado        steamboatpilot             23980   \n",
            "863        Illinois           journalstar            186818   \n",
            "1571  Massachusetts      melrosefreepress           1567610   \n",
            "1126      Louisiana        businessreport            445337   \n",
            "...             ...                   ...               ...   \n",
            "1261          Maine            sunjournal            107376   \n",
            "1821      Minnesota    jacksoncountypilot             10163   \n",
            "351        Colorado  broomfieldenterprise             62449   \n",
            "880        Illinois    thejournalstandard             46283   \n",
            "561         Florida            bocabeacon            680970   \n",
            "\n",
            "      avg_white_pop_pct  avg_median_hh_inc  avg_non_college_pct  \n",
            "1469                  1                  1                    1  \n",
            "505                   1                  1                    0  \n",
            "863                   0                  1                    0  \n",
            "1571                  1                  1                    0  \n",
            "1126                  0                  0                    0  \n",
            "...                 ...                ...                  ...  \n",
            "1261                  1                  0                    1  \n",
            "1821                  1                  1                    1  \n",
            "351                   1                  1                    0  \n",
            "880                   1                  0                    1  \n",
            "561                   0                  0                    1  \n",
            "\n",
            "[1600 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "columns = [\"avg_white_pop_pct\",\"avg_median_hh_inc\",\"avg_non_college_pct\"]\n",
        "df_labels_train = train_df[columns]\n",
        "df_labels_test = test_df[columns]\n",
        "\n",
        "#convert to label lists\n",
        "labels_list_train = df_labels_train.values.tolist()\n",
        "labels_list_test = df_labels_test.values.tolist()\n",
        "\n",
        "# set up our text inputs\n",
        "train_texts = train_df['content'].tolist()\n",
        "train_labels = labels_list_train\n",
        "\n",
        "eval_texts = test_df['content'].tolist()\n",
        "eval_labels = labels_list_test\n",
        "\n",
        "print(train_labels)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
        "\n",
        "#TODO: increase max length when we use article content\n",
        "train_encodings = tokenizer(train_texts, padding=\"max_length\", truncation=True, max_length=64)\n",
        "eval_encodings = tokenizer(eval_texts, padding=\"max_length\", truncation=True, max_length=64)\n",
        "\n",
        "print(train_encodings[0])\n",
        "\n",
        "train_dataset = TextClassifierDataset(train_encodings, train_labels)\n",
        "eval_dataset = TextClassifierDataset(eval_encodings, eval_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4nbuGX16zkF",
        "outputId": "21da9da8-f74b-4245-b427-ddbd86253ffd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 1, 1], [1, 1, 0], [0, 1, 0], [1, 1, 0], [0, 0, 0], [1, 1, 0], [1, 1, 1], [0, 0, 0], [1, 0, 1], [1, 1, 0], [1, 0, 1], [0, 0, 1], [1, 0, 1], [1, 1, 1], [0, 0, 1], [0, 0, 1], [1, 1, 0], [1, 0, 1], [1, 0, 1], [0, 0, 0], [0, 1, 1], [0, 0, 1], [0, 1, 0], [0, 1, 0], [1, 1, 1], [1, 1, 1], [1, 0, 1], [1, 0, 1], [0, 0, 1], [0, 0, 1], [0, 1, 0], [0, 0, 1], [1, 0, 1], [1, 0, 1], [1, 1, 1], [1, 0, 0], [1, 0, 1], [0, 1, 0], [1, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 0], [0, 0, 1], [1, 1, 0], [1, 1, 0], [0, 0, 0], [0, 1, 1], [1, 0, 1], [0, 1, 0], [1, 0, 1], [0, 1, 0], [0, 0, 1], [0, 1, 0], [1, 1, 0], [1, 0, 1], [0, 1, 0], [1, 0, 1], [0, 1, 0], [1, 0, 1], [1, 1, 1], [1, 0, 1], [1, 1, 0], [1, 0, 1], [0, 0, 1], [1, 1, 1], [1, 1, 0], [1, 1, 0], [0, 1, 0], [1, 1, 0], [0, 0, 1], [1, 0, 1], [1, 0, 1], [1, 1, 0], [1, 1, 0], [1, 0, 1], [0, 1, 1], [0, 1, 1], [0, 1, 0], [0, 1, 0], [1, 1, 0], [1, 0, 1], [1, 0, 1], [0, 1, 0], [0, 1, 0], [0, 0, 1], [1, 1, 0], [0, 0, 1], [0, 0, 1], [0, 1, 0], [1, 1, 0], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 1, 1], [1, 1, 0], [0, 0, 1], [1, 0, 1], [1, 1, 1], [1, 0, 1], [0, 0, 1], [1, 1, 0], [1, 0, 1], [1, 0, 1], [1, 0, 1], [0, 1, 0], [1, 1, 0], [1, 1, 0], [1, 1, 0], [1, 1, 0], [1, 1, 0], [0, 1, 0], [1, 1, 0], [1, 0, 1], [1, 1, 0], [0, 0, 1], [1, 1, 0], [0, 1, 1], [1, 0, 1], [1, 0, 1], [0, 1, 0], [0, 1, 0], [0, 1, 0], [1, 1, 1], [1, 1, 0], [1, 1, 0], [1, 0, 1], [1, 1, 1], [1, 0, 0], [0, 1, 0], [1, 0, 1], [0, 0, 1], [1, 1, 0], [0, 1, 0], [0, 1, 0], [0, 1, 1], [1, 1, 0], [1, 1, 1], [1, 1, 0], [1, 0, 1], [0, 1, 0], [1, 0, 1], [1, 1, 0], [1, 1, 1], [1, 0, 1], [0, 1, 0], [1, 1, 1], [1, 1, 0], [0, 1, 0], [0, 0, 0], [0, 0, 1], [1, 1, 0], [0, 0, 1], [1, 1, 0], [0, 0, 0], [1, 1, 0], [1, 1, 0], [1, 1, 0], [1, 0, 1], [1, 1, 1], [1, 0, 1], [0, 0, 0], [1, 0, 0], [1, 0, 1], [1, 0, 1], [1, 1, 0], [1, 1, 0], [1, 1, 0], [0, 0, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [0, 0, 1], [1, 1, 0], [0, 0, 1], [0, 1, 1], [1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [0, 0, 1], [0, 0, 0], [0, 1, 0], [1, 1, 0], [1, 0, 1], [1, 0, 1], [0, 1, 0], [1, 1, 0], [0, 1, 0], [1, 1, 1], [1, 0, 1], [0, 0, 0], [1, 1, 1], [1, 1, 1], [0, 1, 1], [0, 0, 1], [1, 1, 0], [1, 1, 1], [1, 1, 0], [1, 0, 1], [0, 1, 0], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 1, 1], [1, 1, 0], [1, 1, 1], [1, 0, 1], [0, 1, 1], [1, 1, 0], [1, 1, 1], [0, 1, 1], [0, 1, 0], [1, 0, 1], [0, 1, 0], [0, 0, 1], [1, 0, 1], [0, 1, 1], [0, 0, 1], [0, 1, 0], [1, 1, 0], [1, 0, 1], [0, 1, 1], [1, 0, 1], [0, 0, 0], [0, 1, 1], [1, 1, 0], [0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 1], [1, 1, 0], [1, 1, 1], [0, 0, 1], [0, 0, 1], [0, 1, 1], [1, 0, 1], [0, 1, 1], [1, 1, 0], [1, 1, 1], [0, 1, 0], [1, 1, 0], [1, 1, 0], [1, 1, 1], [1, 0, 0], [1, 1, 0], [0, 0, 1], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 1, 1], [1, 1, 0], [0, 1, 0], [0, 0, 1], [1, 0, 1], [0, 1, 0], [1, 1, 1], [0, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1], [0, 0, 0], [1, 1, 0], [1, 1, 0], [0, 1, 0], [1, 1, 0], [1, 0, 1], [0, 1, 0], [0, 1, 1], [1, 1, 1], [0, 1, 0], [1, 0, 1], [1, 1, 0], [1, 1, 0], [0, 1, 0], [0, 1, 1], [1, 0, 1], [1, 1, 0], [1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 1, 0], [0, 0, 1], [0, 1, 0], [0, 0, 0], [1, 1, 0], [1, 1, 1], [0, 1, 1], [0, 0, 1], [1, 1, 0], [1, 0, 1], [1, 1, 0], [1, 0, 1], [1, 0, 1], [1, 0, 1], [1, 1, 0], [0, 0, 1], [1, 0, 1], [1, 0, 1], [0, 1, 0], [1, 1, 0], [0, 0, 1], [0, 1, 0], [1, 1, 0], [0, 1, 0], [0, 0, 1], [1, 1, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 1, 1], [1, 0, 1], [1, 1, 0], [1, 0, 0], [1, 1, 1], [0, 1, 1], [1, 0, 1], [1, 0, 1], [1, 1, 1], [0, 0, 0], [1, 1, 0], [0, 1, 0], [1, 0, 1], [0, 1, 0], [1, 1, 1], [1, 0, 1], [0, 1, 0], [0, 1, 1], [0, 0, 1], [0, 0, 1], [1, 0, 1], [1, 1, 0], [1, 0, 1], [1, 0, 1], [1, 1, 0], [1, 1, 0], [0, 0, 1], [1, 1, 0], [1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 0], [0, 0, 0], [0, 0, 1], [1, 0, 1], [1, 1, 0], [0, 0, 1], [0, 1, 0], [0, 1, 0], [1, 1, 0], [0, 1, 0], [0, 0, 1], [1, 1, 1], [1, 1, 1], [0, 1, 1], [1, 1, 0], [1, 1, 0], [1, 0, 1], [1, 1, 0], [0, 1, 0], [0, 0, 1], [1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 1, 0], [1, 0, 1], [1, 1, 0], [1, 0, 1], [0, 0, 0], [0, 0, 1], [1, 0, 1], [1, 1, 0], [1, 0, 1], [1, 1, 0], [1, 1, 0], [1, 1, 1], [0, 0, 1], [0, 1, 0], [1, 1, 0], [1, 1, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], [1, 0, 1], [0, 0, 1], [1, 1, 0], [0, 1, 0], [1, 1, 0], [1, 0, 1], [1, 0, 0], [1, 1, 0], [0, 0, 1], [1, 1, 0], [0, 1, 1], [1, 1, 0], [0, 0, 1], [1, 1, 0], [0, 1, 0], [0, 1, 0], [1, 1, 0], [1, 1, 0], [1, 1, 0], [1, 1, 0], [0, 1, 0], [0, 0, 1], [1, 0, 1], [1, 1, 0], [1, 1, 0], [1, 1, 0], [1, 1, 0], [0, 1, 1], [1, 1, 0], [1, 0, 1], [1, 1, 0], [0, 1, 0], [1, 1, 0], [0, 0, 1], [0, 1, 1], [0, 0, 0], [0, 1, 0], [1, 1, 1], [1, 1, 0], [0, 1, 0], [0, 0, 1], [1, 0, 1], [0, 1, 0], [0, 0, 1], [0, 0, 0], [1, 1, 0], [1, 1, 0], [0, 1, 0], [0, 1, 0], [0, 0, 0], [0, 1, 0], [1, 0, 1], [1, 1, 1], [1, 1, 0], [0, 0, 0], [0, 0, 1], [1, 1, 0], [1, 0, 1], [1, 0, 1], [1, 1, 0], [0, 1, 0], [1, 1, 0], [0, 0, 1], [1, 0, 1], [0, 0, 1], [0, 0, 1], [0, 1, 0], [1, 0, 1], [1, 1, 1], [1, 1, 1], [1, 0, 1], [1, 1, 0], [0, 1, 1], [1, 0, 1], [1, 1, 0], [1, 0, 1], [1, 0, 1], [0, 1, 0], [1, 0, 1], [1, 1, 0], [1, 1, 0], [1, 1, 0], [1, 1, 1], [1, 1, 0], [1, 1, 0], [1, 1, 0], [1, 0, 1], [1, 1, 0], [1, 1, 1], [0, 1, 0], [1, 0, 1], [0, 0, 1], [0, 0, 1], [1, 1, 0], [0, 1, 0], [0, 0, 1], [0, 1, 0], [1, 1, 0], [0, 0, 1], [1, 0, 1], [0, 0, 1], [0, 0, 1], [1, 0, 1], [1, 0, 1], [0, 1, 0], [1, 0, 1], [1, 1, 0], [0, 0, 1], [1, 0, 1], [0, 0, 0], [1, 1, 0], [1, 1, 0], [1, 0, 0], [1, 1, 0], [1, 1, 0], [1, 0, 1], [0, 0, 1], [0, 0, 0], [1, 0, 1], [1, 1, 1], [1, 1, 0], [1, 1, 0], [1, 1, 0], [0, 1, 0], [1, 1, 1], [0, 0, 1], [1, 1, 0], [0, 1, 0], [0, 1, 1], [0, 0, 0], [0, 0, 0], [1, 0, 1], [1, 1, 0], [0, 1, 0], [1, 1, 0], [0, 0, 1], [1, 1, 0], [1, 1, 0], [0, 1, 0], [1, 1, 1], [0, 1, 1], [1, 0, 1], [1, 0, 1], [1, 1, 0], [1, 1, 1], [1, 1, 0], [1, 1, 0], [0, 0, 0], [0, 0, 1], [1, 0, 1], [1, 0, 0], [1, 1, 1], [1, 0, 1], [1, 0, 1], [1, 0, 1], [1, 1, 0], [1, 1, 1], [0, 1, 1], [1, 0, 1], [1, 1, 0], [1, 0, 1], [1, 0, 1], [1, 1, 0], [1, 1, 0], [1, 1, 1], [1, 0, 1], [1, 0, 1], [1, 0, 1], [0, 0, 0], [0, 0, 1], [1, 1, 0], [1, 0, 0], [1, 1, 0], [1, 0, 1], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], [1, 1, 0], [1, 0, 1], [1, 0, 1], [1, 1, 0], [1, 0, 1], [0, 0, 1], [1, 1, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1], [0, 1, 0], [1, 1, 0], [0, 1, 0], [1, 0, 1], [1, 1, 0], [1, 0, 1], [1, 1, 0], [1, 1, 0], [1, 0, 1], [1, 1, 0], [1, 1, 0], [0, 0, 1], [0, 0, 0], [0, 0, 1], [1, 0, 0], [0, 0, 1], [0, 0, 1], [0, 1, 1], [0, 0, 1], [1, 0, 1], [0, 0, 0], [1, 1, 0], [0, 1, 0], [1, 0, 1], [1, 1, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [1, 1, 0], [1, 1, 0], [1, 1, 1], [0, 0, 0], [0, 0, 1], [1, 0, 1], [0, 0, 1], [1, 0, 1], [0, 0, 1], [0, 1, 0], [1, 1, 0], [0, 1, 0], [0, 0, 1], [1, 1, 0], [1, 1, 1], [1, 1, 0], [1, 1, 1], [0, 1, 1], [0, 1, 0], [1, 0, 1], [1, 0, 1], [1, 1, 0], [1, 0, 1], [1, 0, 1], [0, 1, 0], [1, 1, 0], [1, 1, 0], [0, 0, 1], [1, 1, 1], [1, 1, 0], [1, 0, 1], [0, 0, 1], [1, 1, 0], [0, 1, 0], [1, 1, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], [1, 1, 1], [0, 0, 0], [1, 1, 0], [1, 0, 1], [1, 0, 1], [1, 1, 1], [1, 1, 0], [1, 0, 1], [1, 1, 1], [0, 0, 1], [0, 1, 0], [1, 0, 1], [1, 1, 0], [0, 1, 1], [1, 0, 1], [0, 0, 1], [0, 0, 1], [0, 1, 0], [1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 1, 1], [1, 1, 0], [1, 1, 1], [1, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 0], [1, 1, 1], [1, 1, 0], [1, 1, 1], [0, 1, 0], [0, 1, 0], [0, 0, 1], [0, 1, 1], [1, 1, 1], [0, 0, 0], [1, 1, 0], [1, 0, 1], [1, 1, 0], [1, 1, 0], [0, 1, 0], [1, 1, 0], [1, 1, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 1, 1], [0, 0, 1], [1, 0, 1], [1, 0, 0], [1, 1, 0], [1, 1, 0], [0, 0, 1], [0, 1, 1], [1, 1, 0], [1, 1, 0], [0, 1, 1], [1, 0, 1], [1, 1, 0], [1, 0, 0], [1, 1, 0], [0, 1, 0], [1, 0, 1], [0, 1, 0], [1, 1, 1], [1, 1, 0], [1, 0, 1], [0, 0, 1], [1, 0, 1], [0, 1, 0], [0, 1, 1], [1, 0, 1], [1, 0, 1], [1, 0, 1], [0, 0, 1], [0, 0, 0], [1, 1, 0], [1, 1, 0], [1, 0, 1], [1, 0, 1], [1, 1, 0], [0, 1, 1], [0, 1, 1], [1, 0, 1], [0, 1, 0], [1, 1, 0], [1, 1, 0], [0, 0, 1], [1, 1, 0], [1, 0, 1], [1, 1, 0], [0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 0, 1], [1, 0, 1], [1, 1, 1], [1, 1, 0], [1, 0, 1], [1, 1, 0], [0, 1, 1], [1, 1, 0], [0, 0, 1], [1, 1, 0], [1, 0, 1], [1, 1, 0], [1, 1, 1], [1, 0, 1], [0, 1, 0], [0, 1, 1], [1, 1, 0], [1, 0, 1], [0, 1, 0], [1, 1, 0], [1, 1, 0], [0, 1, 0], [1, 1, 0], [1, 0, 1], [0, 0, 1], [0, 1, 0], [0, 1, 0], [1, 1, 1], [1, 0, 1], [1, 1, 1], [0, 0, 1], [1, 1, 1], [0, 1, 1], [0, 1, 0], [1, 1, 0], [1, 0, 0], [1, 1, 1], [1, 1, 1], [0, 1, 0], [0, 1, 0], [0, 0, 1], [1, 0, 1], [0, 1, 0], [0, 0, 1], [0, 0, 1], [1, 0, 1], [1, 1, 0], [1, 0, 1], [1, 1, 0], [1, 1, 1], [0, 1, 0], [1, 1, 0], [1, 1, 0], [1, 0, 1], [1, 0, 1], [1, 1, 0], [1, 0, 1], [0, 0, 0], [1, 1, 1], [0, 0, 1], [0, 1, 1], [0, 0, 1], [1, 0, 1], [0, 1, 0], [1, 1, 0], [1, 1, 0], [1, 1, 0], [1, 1, 1], [1, 0, 1], [1, 1, 0], [0, 0, 0], [1, 0, 1], [0, 1, 1], [1, 1, 0], [1, 0, 1], [1, 1, 0], [1, 0, 1], [1, 1, 1], [1, 0, 1], [1, 1, 1], [1, 1, 0], [1, 1, 0], [1, 1, 1], [0, 0, 1], [1, 1, 1], [0, 1, 1], [0, 1, 0], [1, 1, 1], [1, 1, 0], [1, 1, 0], [0, 0, 1], [1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 1, 0], [1, 0, 1], [0, 1, 1], [0, 0, 1], [1, 1, 0], [1, 1, 0], [1, 0, 1], [0, 0, 0], [1, 1, 0], [0, 1, 0], [1, 1, 0], [0, 0, 1], [0, 1, 0], [1, 0, 1], [1, 0, 1], [1, 0, 1], [1, 1, 1], [0, 0, 1], [1, 1, 0], [0, 1, 0], [1, 0, 1], [0, 0, 1], [1, 1, 0], [1, 1, 0], [0, 0, 1], [0, 1, 0], [1, 0, 1], [0, 0, 1], [1, 0, 1], [1, 1, 0], [1, 0, 1], [1, 0, 1], [1, 1, 1], [1, 1, 0], [1, 0, 1], [1, 1, 1], [0, 1, 0], [0, 1, 0], [0, 1, 1], [1, 1, 1], [0, 0, 0], [1, 1, 0], [1, 1, 0], [1, 1, 0], [0, 0, 1], [0, 0, 1], [1, 0, 1], [1, 1, 1], [1, 0, 1], [1, 1, 0], [0, 1, 0], [0, 1, 1], [1, 0, 1], [0, 1, 0], [0, 1, 1], [0, 0, 1], [0, 0, 0], [1, 0, 1], [1, 0, 1], [1, 0, 1], [0, 1, 1], [0, 1, 0], [1, 0, 1], [1, 1, 0], [1, 0, 1], [0, 1, 1], [1, 1, 0], [0, 1, 0], [1, 0, 1], [1, 1, 0], [0, 1, 0], [1, 1, 1], [0, 1, 0], [0, 0, 1], [1, 1, 0], [1, 1, 1], [0, 0, 0], [1, 1, 0], [0, 1, 0], [0, 1, 1], [0, 1, 0], [1, 1, 0], [1, 1, 0], [1, 1, 0], [1, 1, 0], [0, 1, 1], [0, 0, 1], [1, 0, 1], [0, 0, 1], [0, 1, 0], [0, 0, 1], [1, 1, 0], [1, 1, 0], [0, 0, 1], [0, 1, 0], [1, 1, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1], [0, 0, 1], [1, 1, 0], [1, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1], [0, 1, 0], [1, 1, 1], [1, 0, 1], [1, 0, 1], [1, 1, 1], [0, 0, 1], [0, 1, 1], [0, 1, 0], [0, 1, 1], [1, 1, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [0, 0, 1], [1, 0, 0], [1, 1, 0], [0, 1, 0], [1, 1, 0], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1], [1, 1, 1], [1, 1, 0], [0, 1, 1], [1, 1, 1], [1, 1, 0], [1, 0, 1], [1, 1, 0], [1, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 0], [0, 1, 1], [0, 0, 1], [1, 1, 1], [1, 1, 0], [0, 1, 0], [1, 1, 0], [0, 1, 0], [0, 1, 0], [1, 1, 0], [1, 0, 0], [0, 0, 1], [1, 1, 0], [0, 0, 1], [0, 1, 0], [1, 0, 1], [1, 1, 0], [1, 1, 0], [1, 1, 0], [1, 1, 0], [0, 0, 1], [1, 0, 1], [1, 0, 1], [0, 1, 0], [1, 1, 0], [1, 1, 1], [1, 1, 1], [0, 0, 1], [1, 0, 1], [0, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 0], [0, 0, 1], [1, 1, 0], [1, 1, 0], [0, 1, 0], [1, 1, 0], [1, 1, 0], [0, 0, 1], [1, 1, 0], [1, 1, 1], [1, 1, 0], [0, 1, 0], [1, 1, 1], [0, 0, 0], [0, 1, 0], [1, 1, 1], [0, 1, 0], [1, 1, 0], [0, 1, 0], [1, 0, 1], [1, 1, 0], [1, 0, 1], [1, 1, 0], [0, 1, 0], [1, 0, 1], [1, 1, 1], [1, 0, 1], [1, 0, 1], [1, 0, 1], [1, 0, 1], [1, 1, 0], [1, 0, 0], [1, 0, 1], [1, 0, 0], [1, 0, 0], [1, 1, 1], [1, 1, 0], [1, 0, 1], [0, 1, 0], [0, 0, 1], [0, 1, 1], [0, 0, 1], [0, 1, 0], [0, 0, 1], [0, 1, 1], [0, 0, 1], [1, 1, 1], [0, 1, 0], [0, 0, 0], [0, 1, 0], [1, 0, 1], [0, 1, 0], [0, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 0], [1, 1, 0], [0, 1, 0], [0, 1, 1], [0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 0, 1], [1, 1, 0], [1, 0, 1], [0, 0, 1], [1, 0, 1], [0, 1, 0], [1, 1, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [0, 1, 0], [1, 0, 1], [0, 1, 0], [1, 0, 1], [1, 0, 1], [1, 1, 0], [0, 0, 1], [0, 1, 0], [1, 0, 1], [0, 0, 1], [0, 0, 0], [1, 0, 1], [1, 1, 0], [0, 0, 1], [0, 0, 1], [1, 1, 1], [1, 0, 1], [1, 1, 0], [1, 1, 1], [0, 0, 1], [1, 1, 1], [1, 0, 1], [1, 0, 1], [1, 1, 0], [1, 0, 1], [1, 1, 0], [0, 0, 1], [1, 1, 0], [0, 1, 0], [0, 0, 1], [1, 1, 0], [1, 1, 0], [1, 1, 0], [1, 1, 0], [1, 1, 0], [1, 0, 1], [1, 1, 0], [1, 0, 1], [0, 0, 1], [1, 1, 1], [1, 1, 0], [1, 1, 0], [0, 1, 1], [1, 1, 0], [0, 0, 1], [0, 1, 0], [1, 1, 0], [0, 0, 0], [1, 1, 0], [0, 0, 0], [1, 1, 0], [1, 1, 0], [1, 1, 0], [1, 1, 0], [1, 1, 0], [0, 0, 0], [1, 0, 1], [1, 1, 1], [0, 1, 0], [0, 1, 1], [1, 1, 1], [1, 1, 0], [1, 1, 0], [1, 1, 0], [1, 1, 0], [0, 1, 0], [1, 1, 0], [0, 1, 0], [0, 0, 1], [0, 1, 1], [0, 1, 0], [1, 0, 1], [1, 1, 0], [1, 1, 1], [0, 0, 1], [1, 1, 0], [0, 1, 0], [0, 0, 1], [0, 0, 0], [1, 1, 0], [1, 0, 1], [0, 1, 1], [1, 1, 0], [1, 1, 0], [0, 1, 0], [1, 1, 1], [1, 1, 0], [1, 0, 1], [0, 1, 0], [1, 1, 0], [1, 1, 0], [1, 1, 1], [1, 0, 1], [1, 1, 0], [0, 1, 0], [0, 0, 0], [1, 1, 0], [1, 1, 0], [1, 0, 0], [1, 1, 0], [0, 1, 0], [0, 0, 1], [1, 1, 0], [1, 1, 0], [0, 0, 1], [0, 0, 1], [0, 0, 0], [1, 1, 0], [1, 1, 0], [0, 1, 1], [1, 0, 1], [1, 1, 1], [0, 0, 0], [1, 1, 0], [0, 1, 0], [1, 0, 1], [0, 1, 0], [1, 0, 0], [1, 1, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [1, 0, 0], [0, 1, 0], [1, 0, 1], [1, 1, 0], [0, 0, 1], [0, 1, 0], [1, 1, 1], [1, 0, 1], [1, 1, 1], [0, 1, 0], [0, 1, 0], [1, 1, 1], [0, 1, 0], [1, 0, 1], [0, 1, 0], [0, 0, 1], [1, 1, 0], [1, 0, 1], [1, 1, 0], [1, 1, 0], [0, 1, 0], [1, 0, 1], [1, 1, 1], [1, 1, 0], [0, 0, 1], [0, 1, 1], [0, 0, 0], [1, 1, 1], [1, 1, 1], [1, 0, 1], [1, 0, 1], [1, 0, 1], [0, 1, 0], [1, 1, 0], [0, 0, 1], [0, 0, 1], [1, 1, 1], [0, 0, 1], [1, 1, 1], [0, 1, 0], [1, 0, 0], [0, 1, 0], [1, 1, 1], [1, 1, 0], [0, 1, 0], [1, 1, 0], [1, 0, 0], [0, 0, 1], [0, 1, 0], [1, 1, 0], [1, 1, 1], [0, 0, 0], [0, 1, 1], [1, 1, 0], [0, 1, 0], [1, 1, 0], [0, 0, 0], [0, 0, 0], [0, 1, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 0], [0, 0, 1], [0, 0, 1], [1, 1, 0], [0, 0, 1], [0, 0, 0], [0, 0, 1], [0, 0, 1], [0, 1, 0], [1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 1, 0], [1, 1, 0], [1, 1, 0], [1, 0, 1], [1, 1, 0], [0, 1, 0], [1, 1, 0], [0, 1, 0], [0, 1, 1], [1, 1, 0], [0, 0, 0], [0, 0, 1], [1, 0, 1], [0, 0, 1], [1, 1, 0], [1, 1, 0], [1, 1, 0], [0, 1, 1], [0, 0, 1], [1, 0, 0], [1, 0, 1], [1, 1, 0], [0, 0, 1], [1, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 1, 0], [0, 0, 1], [1, 0, 1], [0, 0, 1], [1, 1, 1], [0, 0, 1], [1, 1, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [1, 0, 1], [1, 1, 0], [1, 0, 1], [1, 0, 0], [0, 1, 0], [0, 1, 0], [1, 0, 0], [0, 0, 1], [1, 1, 0], [1, 1, 0], [1, 1, 0], [0, 0, 1], [1, 1, 0], [0, 0, 1], [1, 1, 0], [1, 0, 1], [1, 0, 1], [0, 1, 0], [1, 1, 0], [0, 0, 1], [1, 1, 0], [1, 1, 0], [1, 0, 1], [1, 1, 0], [1, 1, 0], [0, 1, 1], [0, 0, 1], [0, 0, 1], [1, 0, 0], [1, 1, 1], [0, 0, 1], [1, 1, 1], [1, 0, 1], [1, 1, 0], [1, 0, 1], [1, 1, 1], [0, 0, 1], [1, 1, 0], [1, 0, 1], [0, 0, 0], [0, 1, 0], [0, 1, 0], [1, 1, 0], [0, 0, 1], [0, 0, 1], [1, 1, 0], [0, 0, 1], [1, 1, 1], [1, 1, 0], [1, 1, 0], [1, 0, 1], [1, 0, 1], [0, 1, 0], [1, 1, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], [1, 1, 0], [1, 1, 0], [1, 0, 1], [0, 0, 1], [0, 1, 0], [1, 1, 1], [0, 0, 1], [1, 1, 0], [1, 0, 1], [1, 0, 1], [1, 1, 0], [1, 0, 1], [1, 1, 0], [1, 1, 0], [1, 1, 0], [1, 1, 0], [0, 1, 0], [1, 1, 0], [0, 0, 1], [1, 1, 0], [0, 1, 1], [1, 1, 0], [0, 1, 0], [0, 0, 1], [0, 1, 0], [1, 0, 1], [1, 1, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0], [1, 0, 1], [0, 0, 1], [0, 1, 1], [1, 1, 0], [0, 0, 0], [0, 0, 0], [1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 1, 0], [0, 1, 0], [1, 1, 0], [1, 1, 0], [0, 0, 0], [1, 1, 0], [0, 1, 0], [0, 0, 1], [1, 0, 1], [1, 1, 1], [1, 1, 0], [0, 0, 1], [1, 1, 0], [0, 0, 1], [0, 1, 0], [1, 1, 0], [0, 1, 0], [0, 1, 0], [1, 1, 0], [1, 1, 0], [0, 0, 1], [0, 0, 1], [0, 0, 0], [1, 1, 0], [1, 0, 0], [0, 0, 1], [1, 0, 1], [1, 0, 0], [1, 1, 0], [0, 1, 1], [1, 1, 0], [1, 1, 0], [0, 0, 1], [1, 0, 1], [1, 1, 0], [1, 1, 0], [0, 1, 0], [1, 0, 1], [1, 1, 0], [0, 1, 0], [1, 1, 1], [1, 0, 1], [1, 0, 1], [1, 0, 1], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 1, 1], [1, 1, 0], [0, 1, 0], [0, 1, 1], [1, 0, 1], [1, 1, 1], [0, 0, 1], [1, 1, 1], [0, 1, 0], [0, 1, 0], [0, 0, 1], [1, 1, 1], [0, 0, 0], [1, 0, 1], [0, 1, 1], [1, 0, 1], [0, 1, 0], [1, 1, 0], [1, 0, 1], [1, 1, 0], [0, 0, 1], [0, 0, 0], [0, 1, 0], [0, 1, 0], [1, 1, 0], [0, 1, 0], [1, 1, 0], [1, 1, 0], [1, 1, 0], [0, 0, 1], [0, 0, 1], [0, 0, 0], [0, 0, 1], [0, 1, 1], [0, 0, 1], [1, 0, 0], [1, 0, 1], [1, 0, 1], [1, 1, 1], [1, 1, 0], [1, 1, 0], [0, 1, 0], [1, 1, 1], [1, 1, 1], [0, 1, 0], [0, 1, 1], [0, 1, 1], [1, 0, 1], [0, 1, 0], [0, 0, 0], [1, 0, 1], [0, 1, 0], [1, 1, 0], [0, 1, 0], [0, 0, 1], [1, 1, 0], [1, 1, 0], [0, 0, 0], [1, 1, 0], [0, 1, 1], [1, 1, 0], [0, 0, 0], [1, 0, 1], [0, 1, 1], [1, 1, 0], [0, 0, 1], [1, 0, 1], [0, 0, 1], [0, 1, 0], [0, 1, 1], [0, 0, 1], [1, 1, 0], [0, 0, 1], [0, 1, 0], [1, 1, 0], [0, 1, 0], [1, 1, 1], [0, 1, 1], [0, 1, 0], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1], [1, 1, 0], [1, 1, 0], [1, 1, 0], [0, 1, 0], [1, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 0], [1, 1, 0], [0, 0, 0], [0, 1, 0], [1, 1, 1], [1, 0, 1], [1, 0, 0], [1, 1, 0], [0, 0, 1], [1, 1, 0], [1, 1, 0], [1, 0, 1], [0, 1, 0], [0, 1, 0], [0, 0, 1], [1, 1, 0], [1, 1, 1], [1, 1, 0], [0, 0, 1], [1, 0, 0], [1, 1, 0], [1, 1, 0], [0, 1, 0], [1, 1, 1], [1, 1, 0], [1, 0, 1], [1, 1, 1], [0, 0, 0], [0, 0, 1], [1, 1, 0], [0, 1, 1], [1, 1, 0], [1, 1, 1], [1, 1, 0], [1, 1, 0], [1, 0, 1], [0, 1, 0], [1, 1, 0], [1, 0, 0], [1, 1, 0], [0, 0, 1], [1, 1, 0], [0, 0, 1], [0, 1, 1], [0, 1, 0], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 1, 1], [1, 1, 0], [1, 0, 1], [0, 0, 1]]\n",
            "Encoding(num_tokens=64, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "id": "ntr-xcP-7PWD",
        "outputId": "dc8c12dc-3e4c-4f3f-dc3f-b57d81b38a57"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Collecting transformers[torch]\n",
            "  Downloading transformers-4.39.2-py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.28.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.4.99)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.38.2\n",
            "    Uninstalling transformers-4.38.2:\n",
            "      Successfully uninstalled transformers-4.38.2\n",
            "Successfully installed transformers-4.39.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "transformers"
                ]
              },
              "id": "ec2a1a5254af420685f2e86207044756"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    problem_type=\"multi_label_classification\",\n",
        "    num_labels=3\n",
        ")\n",
        "\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=\"./output\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=4\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = training_arguments,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.save_model(output_dir='./trained_bert')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "t7ejxBh863Jh",
        "outputId": "f16ed750-2f2d-480d-8f2f-a194bd89e76d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [400/400 01:18, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.546294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.513811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.533316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.552115</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Evaluate the model\n",
        "results = trainer.evaluate()\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "qUvrM0Bo7HVc",
        "outputId": "8bd2b222-9798-4e78-c41a-9bf7bbf716ab"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5521154999732971, 'eval_runtime': 1.4365, 'eval_samples_per_second': 278.454, 'eval_steps_per_second': 17.403, 'epoch': 4.0}\n"
          ]
        }
      ]
    }
  ]
}